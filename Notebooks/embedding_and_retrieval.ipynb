{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e13661ca",
   "metadata": {},
   "source": [
    "## Embedding and Retrieval\n",
    "\n",
    "- LLMs have been trained with huge corpus of data. Yet they lack information about internal/confidential data within organization.\n",
    "- Methods to make LLM infer your data\n",
    "  - Fine-Tuning\n",
    "  - RAG\n",
    "- RAG is a first step to provide additional context to LLM to start using your internal data\n",
    "- Components of RAG\n",
    "    - Data Preparation (Extraction, Chunking)\n",
    "    - Embedding\n",
    "    - Storing in Vector DB\n",
    "    - Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3796321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Llama-index as a LLM framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b218855",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "- Using a Youtube Video Transcript Extractor as Data Loader from YT videos\n",
    "- Load the source and split into granular chunks for embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7230842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents from YouTube transcripts.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Using Youtube transcripts as a data source\n",
    "from llama_index.readers.youtube_transcript import YoutubeTranscriptReader\n",
    "YOUTUBE_VIDEO_LINKS = [\"https://youtu.be/LCEmiRjPEtQ?si=YYiRBrq7Ho3NYf6F\", \"https://youtu.be/c3b-JASoPi0?si=9kk_0wF7e5d5oXBY\"]\n",
    "\n",
    "data_loader = YoutubeTranscriptReader()\n",
    "documents = data_loader.load_data(\n",
    "    ytlinks=YOUTUBE_VIDEO_LINKS,\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents from YouTube transcripts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0465c3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 2/2 [00:00<00:00, 18.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The documents have been split into 50 chunks.\n",
      "\n",
      "\n",
      "Please welcome former director of AI\n",
      "Tesla Andre Carpathy.\n",
      "[Music]\n",
      "Hello.\n",
      "[Music]\n",
      "Wow, a lot of people here. Hello.\n",
      "Um, okay. Yeah. So I'm excited to be\n",
      "here today to talk to you about software\n",
      "in the era of AI. And I'm told that many\n",
      "of you are students like bachelors,\n",
      "masters, PhD and so on. And you're about\n",
      "to enter the industry. And I think it's\n",
      "actually like an extremely unique and\n",
      "very interesting time to enter the\n",
      "industry right now. And I think\n",
      "fundamentally the reason for that is\n",
      "that um software is changing uh again.\n",
      "And I say again because I actually gave\n",
      "this talk already. Um but the problem is\n",
      "that software keeps changing. So I\n",
      "actually have a lot of material to\n",
      "create new talks and I think it's\n",
      "changing quite fundamentally. I think\n",
      "roughly speaking software has not\n",
      "changed much on such a fundamental level\n",
      "for 70 years. And then it's changed I\n",
      "think about twice quite rapidly in the\n",
      "last few years. And so there's just a\n",
      "huge amount of work to do a huge amount\n",
      "of software to write and rewrite. So\n",
      "let's take a look at maybe the realm of\n",
      "software. So if we kind of think of this\n",
      "as like the map of software this is a\n",
      "really cool tool called map of GitHub.\n",
      "Um this is kind of like all the software\n",
      "that's written. Uh these are\n",
      "instructions to the computer for\n",
      "carrying out tasks in the digital space.\n",
      "So if you zoom in here, these are all\n",
      "different kinds of repositories and this\n",
      "is all the code that has been written.\n",
      "And a few years ago I kind of observed\n",
      "that um software was kind of changing\n",
      "and there was kind of like a new type of\n",
      "software around and I called this\n",
      "software 2.0 at the time and the idea\n",
      "here was that software 1.0 is the code\n",
      "you write for the computer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.text_splitter import SentenceSplitter\n",
    "\n",
    "CHUNK_SIZE = 500  # Define the chunk size for splitting sentences\n",
    "CHUNK_OVERLAP = 50\n",
    "\n",
    "sentence_splitter = SentenceSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    ")\n",
    "\n",
    "chunks = sentence_splitter.get_nodes_from_documents(documents, show_progress=True)\n",
    "\n",
    "print(f\"The documents have been split into {len(chunks)} chunks.\\n\\n\")\n",
    "\n",
    "print(chunks[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532c699d",
   "metadata": {},
   "source": [
    "## Embedding the source\n",
    "\n",
    "- Use local embedding model from Hugging Face\n",
    "- Embedding Model used here is - `intfloat/multilingual-e5-large-instruct`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c48b3194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "EMBEDDING_MODEL_NAME = \"intfloat/multilingual-e5-large-instruct\"\n",
    "embed_model = HuggingFaceEmbedding(model_name=EMBEDDING_MODEL_NAME, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83acc22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    }
   ],
   "source": [
    "for chunk in chunks:\n",
    "    chunk.embedding = embed_model.get_text_embedding(chunk.text)\n",
    "\n",
    "print(len(chunks[0].embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e39fde56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Qdrant-DB from as a vector database\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "import qdrant_client\n",
    "\n",
    "QDRANT_URL = \"http://localhost:6333\"\n",
    "COLLECTION_NAME = \"Understanding_AI_Agents\"\n",
    "\n",
    "def get_vector_store():\n",
    "    client = qdrant_client.QdrantClient(\n",
    "        url=QDRANT_URL,\n",
    "\n",
    "    )\n",
    "\n",
    "    vector_store = QdrantVectorStore(\n",
    "        client=client,\n",
    "        collection_name=COLLECTION_NAME,\n",
    "    )\n",
    "    return vector_store\n",
    "\n",
    "qdrant_vector_store = get_vector_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85ee7ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0dc628ed-2777-488d-a5b2-5f6a0db62ef1',\n",
       " '29148353-c4d0-4b6c-9d04-881a4e0ef786',\n",
       " '0dfe7f7d-374d-4b2d-884f-39d296cc1e5f',\n",
       " '76b0661b-65f6-47e6-a400-2be2128adf9d',\n",
       " 'caab1d8e-d675-4bab-a47d-cf64c6918fa4',\n",
       " '22b39cb1-60b8-4466-b32f-c529414c421b',\n",
       " 'dc4bbb96-bfa3-4f7c-b807-f7e477f86918',\n",
       " 'ccab07b2-3209-4a13-9e99-f2402fda35c0',\n",
       " 'df3ecf17-1a1b-4d07-9f5f-83aac58fb852',\n",
       " '79f3bb4f-a675-4709-bda7-fc42882f8ffd',\n",
       " 'e7426219-08a8-4754-b115-41ef9953a64d',\n",
       " 'df394fcc-7c7c-41ef-a99c-2782ce6caa2e',\n",
       " 'cddb69c0-f9c5-4836-8c4e-8754691d55a7',\n",
       " 'f8658ccb-da32-46c4-abdc-29c854cb86a6',\n",
       " '8eaf5bd1-4fb7-4964-9f24-4d427127369b',\n",
       " '9ded4459-0935-41ea-97c4-067c9f1b7124',\n",
       " '33a1ca58-507e-43bf-b7b1-7b5df09fcd6e',\n",
       " 'dd5ac7cf-3a57-40b2-b558-4d9c391b81ae',\n",
       " '00de744b-2f9d-4b96-b46c-1d796f3abbf3',\n",
       " '2cf829c2-57dd-4e70-a532-22ff8abc175f',\n",
       " '127c310d-5185-43e3-9112-948b79e7bcbb',\n",
       " '36814c9b-ba99-4f7e-9c66-78dab5b4f7b7',\n",
       " '14ac6d04-7de9-4f16-a70e-28e684b840c1',\n",
       " '9229249c-9750-49d7-8c73-398b657fc3ff',\n",
       " 'b358d3a6-9d32-4bfa-abd9-279f09b3bc49',\n",
       " 'efbb09f6-373d-4cbe-9b44-7bcd98c71f6a',\n",
       " '4236ef3f-5f3b-4704-8e56-a253708817e1',\n",
       " 'f8879ff3-98f5-4b5a-a4bd-930dcefba468',\n",
       " 'e56e5739-8219-4956-99a5-269d145a892a',\n",
       " 'bf723b7b-feae-42bb-98ed-b2ff375f4525',\n",
       " 'ec313098-5a55-454e-8b53-b88319d175e2',\n",
       " 'b30136a4-2013-429f-b231-2be4204ec926',\n",
       " '1578e718-9022-4a5b-bdd6-c2006f1c9376',\n",
       " '5cec5d5e-8080-4003-be9c-4d7889807722',\n",
       " 'b66bce4d-f36d-4ca8-8685-bd649cd451ed',\n",
       " '660d3c86-e01a-42e7-9cb9-4703cb5281de',\n",
       " 'ba8f2686-c331-46b2-bfb5-d5f74bd1cd1d',\n",
       " '033fd4e7-6600-43c4-9561-1a0a498accf4',\n",
       " '6de27d7f-c279-4aaa-82bd-c920392450d8',\n",
       " 'a10d56f3-e350-4dce-b7da-69ae5ec1b7fd',\n",
       " 'aab175c1-9fea-4278-b3e7-c62c2edf6706',\n",
       " 'c51d723b-a912-488d-a3d7-9e4fd2ba6fbe',\n",
       " 'deb4257d-c536-4b86-bd5a-d968ef0eb1f2',\n",
       " '95973664-5222-4dd0-a8e5-82cd77aef2af',\n",
       " '115ce736-73e7-4d7d-b81d-66bf1e5edc21',\n",
       " 'ea315e62-7312-430e-b544-5d083b1b3774',\n",
       " 'c33f4b18-c08b-43b3-906d-976433d0484d',\n",
       " 'f997206a-6e6b-4f77-a855-6c69bed331b9',\n",
       " '2b4da997-ad47-4a58-b007-7a0fcf947572',\n",
       " 'fdd2ab5f-a1b6-4e4d-81b4-815dc587ceb6']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the chunks to the Qdrant vector store\n",
    "\n",
    "_ = qdrant_vector_store.add(\n",
    "    nodes=chunks,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87b44ac",
   "metadata": {},
   "source": [
    "## Retrieval\n",
    "\n",
    "1. Since we have embedded the current document, we can use a query and retrieve a document before summarization.\n",
    "2. Create a retriever from vector Store for retrieving relevant documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7a5eb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import QueryBundle\n",
    "\n",
    "query = \"what is software 3.0? by Andrej Karpathy\"\n",
    "\n",
    "query_embeddings = embed_model.get_text_embedding(query)\n",
    "\n",
    "query_bundle = QueryBundle(query_str=\"\", embedding=query_embeddings)\n",
    "\n",
    "print(len(query_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a2c45d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "SIMILARITY_TOP_K = 3\n",
    "\n",
    "vector_store_index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=qdrant_vector_store, embed_model=embed_model\n",
    ")\n",
    "\n",
    "qdrant_retriever = vector_store_index.as_retriever(similarity_top_k=SIMILARITY_TOP_K)\n",
    "retrieved_nodes = qdrant_retriever.retrieve(query_bundle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c5cd813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Node: Software 2.0\n",
      "know are basically neural networks and\n",
      "in particular the weights of a neural\n",
      "network and you're not writing this code\n",
      "directly you are most you are more kind\n",
      "of like tuning the data sets and then\n",
      "you're running an optimizer to create to\n",
      "create the parameters of this neural net\n",
      "and I think like at the time neural nets\n",
      "were kind of seen as like just a\n",
      "different kind of classifier like a\n",
      "decision tree or something like that and\n",
      "so I think it was kind of like um I\n",
      "think this framing was a lot more\n",
      "appropriate and now actually what we\n",
      "have is kind of like an equivalent of\n",
      "GitHub in the realm of software 2.0 And\n",
      "I think the hugging face is basically\n",
      "equivalent of GitHub in software 2.0.\n",
      "And there's also model atlas and you can\n",
      "visualize all the code written there. In\n",
      "case you're curious, by the way, the\n",
      "giant circle, the point in the middle,\n",
      "uh these are the parameters of flux, the\n",
      "image generator. And so anytime someone\n",
      "tunes a on top of a flux model, you\n",
      "basically create a git commit uh in this\n",
      "space and uh you create a different kind\n",
      "of a image generator. So basically what\n",
      "we have is software 1.0 is the computer\n",
      "code that programs a computer. Software\n",
      "2.0 are the weights which program neural\n",
      "networks. Uh and here's an example of\n",
      "Alexet image recognizer neural network.\n",
      "Now so far all of the neural networks\n",
      "that we've been familiar with until\n",
      "recently where kind of like fixed\n",
      "function computers image to categories\n",
      "or something like that. And I think\n",
      "what's changed and I think is a quite\n",
      "fundamental change is that neural\n",
      "networks became programmable with large\n",
      "language models. And so I I see this as\n",
      "quite new, unique. It's a new kind of a\n",
      "computer and uh so in my mind it's uh\n",
      "worth giving it a new designation of\n",
      "software 3.0. And basically your prompts\n",
      "are now programs that program the LLM.\n",
      "And uh remarkably uh these uh prompts\n",
      "are written in English. So it's kind of\n",
      "a very interesting programming language.\n",
      "\n",
      "Similarity Score: 0.8805625\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Retrieved Node: Please welcome former director of AI\n",
      "Tesla Andre Carpathy.\n",
      "[Music]\n",
      "Hello.\n",
      "[Music]\n",
      "Wow, a lot of people here. Hello.\n",
      "Um, okay. Yeah. So I'm excited to be\n",
      "here today to talk to you about software\n",
      "in the era of AI. And I'm told that many\n",
      "of you are students like bachelors,\n",
      "masters, PhD and so on. And you're about\n",
      "to enter the industry. And I think it's\n",
      "actually like an extremely unique and\n",
      "very interesting time to enter the\n",
      "industry right now. And I think\n",
      "fundamentally the reason for that is\n",
      "that um software is changing uh again.\n",
      "And I say again because I actually gave\n",
      "this talk already. Um but the problem is\n",
      "that software keeps changing. So I\n",
      "actually have a lot of material to\n",
      "create new talks and I think it's\n",
      "changing quite fundamentally. I think\n",
      "roughly speaking software has not\n",
      "changed much on such a fundamental level\n",
      "for 70 years. And then it's changed I\n",
      "think about twice quite rapidly in the\n",
      "last few years. And so there's just a\n",
      "huge amount of work to do a huge amount\n",
      "of software to write and rewrite. So\n",
      "let's take a look at maybe the realm of\n",
      "software. So if we kind of think of this\n",
      "as like the map of software this is a\n",
      "really cool tool called map of GitHub.\n",
      "Um this is kind of like all the software\n",
      "that's written. Uh these are\n",
      "instructions to the computer for\n",
      "carrying out tasks in the digital space.\n",
      "So if you zoom in here, these are all\n",
      "different kinds of repositories and this\n",
      "is all the code that has been written.\n",
      "And a few years ago I kind of observed\n",
      "that um software was kind of changing\n",
      "and there was kind of like a new type of\n",
      "software around and I called this\n",
      "software 2.0 at the time and the idea\n",
      "here was that software 1.0 is the code\n",
      "you write for the computer.\n",
      "\n",
      "Similarity Score: 0.8741159\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Retrieved Node: Now,\n",
      "when I was at uh Tesla, um we were\n",
      "working on the uh autopilot and uh we\n",
      "were trying to get the car to drive and\n",
      "I sort of showed this slide at the time\n",
      "where you can imagine that the inputs to\n",
      "the car are on the bottom and they're\n",
      "going through a software stack to\n",
      "produce the steering and acceleration\n",
      "and I made the observation at the time\n",
      "that there was a ton of C++ code around\n",
      "in the autopilot which was the software\n",
      "1.0 code and then there was some neural\n",
      "nets in there doing image recognition\n",
      "and uh I kind of observed that over time\n",
      "as we made the autopilot better\n",
      "basically the neural network grew in\n",
      "capability and size and in addition to\n",
      "that all the C++ code was being deleted\n",
      "and kind of like was um and a lot of the\n",
      "kind of capabilities and functionality\n",
      "that was originally written in 1.0 was\n",
      "migrated to 2.0. So as an example, a lot\n",
      "of the stitching up of information\n",
      "across images from the different cameras\n",
      "and across time was done by a neural\n",
      "network and we were able to delete a lot\n",
      "of code and so the software 2.0 stack\n",
      "quite literally ate through the software\n",
      "stack of the autopilot. So I thought\n",
      "this was really remarkable at the time\n",
      "and I think we're seeing the same thing\n",
      "again where uh basically we have a new\n",
      "kind of software and it's eating through\n",
      "the stack. We have three completely\n",
      "different programming paradigms and I\n",
      "think if you're entering the industry\n",
      "it's a very good idea to be fluent in\n",
      "all of them because they all have slight\n",
      "pros and cons and you may want to\n",
      "program some functionality in 1.0 or 2.0\n",
      "or 3.0. Are you going to train\n",
      "neurallet? Are you going to just prompt\n",
      "an LLM? Should this be a piece of code\n",
      "that's explicit etc. So we all have to\n",
      "make these decisions and actually\n",
      "potentially uh fluidly trans transition\n",
      "between these paradigms.\n",
      "\n",
      "Similarity Score: 0.8683933\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for node in retrieved_nodes:\n",
    "    print(f\"Retrieved Node: {node.text}\\n\")\n",
    "    print(f\"Similarity Score: {node.score}\\n\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76da3c97",
   "metadata": {},
   "source": [
    "## Further Reads & References\n",
    "\n",
    "1. Embedding Modes Benchmark - https://huggingface.co/spaces/mteb/leaderboard\n",
    "2. llama-hub - https://llamahub.ai/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "understanding-ai-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
